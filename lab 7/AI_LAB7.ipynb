{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1\n"
      ],
      "metadata": {
        "id": "0IdQuMth_EUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the car dataset from CSV\n",
        "url = \"car.csv\"\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Assign column names\n",
        "column_names = [\"buying\", \"maint\", \"doors\", \"person\", \"lug_boot\", \"safety\", \"class\"]\n",
        "df.columns = column_names\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = pd.get_dummies(df.drop(\"class\", axis=1))  # One-hot encoding for categorical variables\n",
        "y = df[\"class\"]\n",
        "\n",
        "# Split the data into training (60%) and testing (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
        "\n",
        "# Create a Decision Tree classifier with entropy as the criterion and max_depth=None\n",
        "clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=None)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance using confusion matrix and F1-score\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the confusion matrix and F1 score\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSe7O6dK8ISz",
        "outputId": "f40c5d0c-9f53-40b0-889e-f3e212b77237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[137   3  13   1]\n",
            " [  2  26   0   0]\n",
            " [  2   0 482   0]\n",
            " [  2   0   0  24]]\n",
            "F1 Score: 0.966290161302619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2"
      ],
      "metadata": {
        "id": "Ff7m3dve_HLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "# Load the car dataset from CSV\n",
        "url = \"car.csv\"\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Assign column names\n",
        "column_names = [\"buying\", \"maint\", \"doors\", \"person\", \"lug_boot\", \"safety\", \"class\"]\n",
        "df.columns = column_names\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = pd.get_dummies(df.drop(\"class\", axis=1))  # One-hot encoding for categorical variables\n",
        "y = df[\"class\"]\n",
        "\n",
        "# Split the data into training (60%) and testing (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
        "\n",
        "# Number of repetitions\n",
        "num_repeats = 20\n",
        "# Lists to store results\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "# Define a range of max_depth values to test\n",
        "max_depth_values = [3, 5, 7, 10, 15, 20,25, None]\n",
        "for max_depth in max_depth_values:\n",
        "    f1_scores_iter = []\n",
        "    conf_matrices_iter = []\n",
        "    for _ in range(num_repeats):\n",
        "        # Split the data into training (60%) and testing (40%)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                             test_size=0.4, stratify=y)\n",
        "        # Create a Decision Tree classifier with entropy as the criterion\n",
        "        clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42,\n",
        "                                     max_depth=max_depth)\n",
        "        # Train the classifier on the training data\n",
        "        clf.fit(X_train, y_train)\n",
        "        # Make predictions on the test data\n",
        "        y_pred = clf.predict(X_test)\n",
        "        # Evaluate the performance using confusion matrix and F1-score\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        # Store results\n",
        "        conf_matrices_iter.append(conf_matrix)\n",
        "        f1_scores_iter.append(f1)\n",
        "\n",
        "    # Calculate and print the average F1-score and confusion matrix for the current max_depth\n",
        "    average_f1_iter = np.mean(f1_scores_iter, axis=0)\n",
        "    average_conf_matrix_iter = np.mean(conf_matrices_iter, axis=0)\n",
        "    print(f\"\\nMax Depth: {max_depth}\")\n",
        "    print(\"Average Confusion Matrix:\")\n",
        "    print(average_conf_matrix_iter.astype(int))\n",
        "    print(\"Average F1 Score:\", average_f1_iter)\n",
        "    # Store results for all max_depth values\n",
        "    f1_scores.append(average_f1_iter)\n",
        "    conf_matrices.append(average_conf_matrix_iter)\n",
        "# Find the max_depth that gives the highest average F1-score\n",
        "best_max_depth_index = np.argmax(f1_scores)\n",
        "best_max_depth = max_depth_values[best_max_depth_index]\n",
        "print(\"\\nBest Max Depth:\", best_max_depth)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKjwLUN18Zbt",
        "outputId": "6d9fd0a9-60bf-46a3-a2b8-c54494af1462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Max Depth: 3\n",
            "Average Confusion Matrix:\n",
            "[[128   0  25   0]\n",
            " [ 28   0   0   0]\n",
            " [ 62   0 421   0]\n",
            " [ 26   0   0   0]]\n",
            "Average F1 Score: 0.7755432081985887\n",
            "\n",
            "Max Depth: 5\n",
            "Average Confusion Matrix:\n",
            "[[148   2   0   2]\n",
            " [ 19   4   0   4]\n",
            " [ 53   0 429   0]\n",
            " [ 15   2   0   7]]\n",
            "Average F1 Score: 0.8431097568125987\n",
            "\n",
            "Max Depth: 7\n",
            "Average Confusion Matrix:\n",
            "[[139   3   4   6]\n",
            " [  6  16   0   4]\n",
            " [ 25   0 457   0]\n",
            " [  2   0   0  22]]\n",
            "Average F1 Score: 0.9183385475624786\n",
            "\n",
            "Max Depth: 10\n",
            "Average Confusion Matrix:\n",
            "[[144   3   4   1]\n",
            " [  3  23   0   1]\n",
            " [  8   0 474   0]\n",
            " [  1   1   0  23]]\n",
            "Average F1 Score: 0.9622170799463339\n",
            "\n",
            "Max Depth: 15\n",
            "Average Confusion Matrix:\n",
            "[[145   2   5   0]\n",
            " [  2  23   0   0]\n",
            " [  6   0 477   0]\n",
            " [  1   1   0  23]]\n",
            "Average F1 Score: 0.9675345383034737\n",
            "\n",
            "Max Depth: 20\n",
            "Average Confusion Matrix:\n",
            "[[142   1   9   0]\n",
            " [  3  23   0   0]\n",
            " [  6   1 476   0]\n",
            " [  1   1   0  22]]\n",
            "Average F1 Score: 0.961283169010767\n",
            "\n",
            "Max Depth: 25\n",
            "Average Confusion Matrix:\n",
            "[[143   2   7   1]\n",
            " [  3  23   0   1]\n",
            " [  6   0 476   0]\n",
            " [  1   1   0  23]]\n",
            "Average F1 Score: 0.9638007098789958\n",
            "\n",
            "Max Depth: None\n",
            "Average Confusion Matrix:\n",
            "[[143   2   6   1]\n",
            " [  2  24   0   0]\n",
            " [  6   0 476   0]\n",
            " [  2   1   0  22]]\n",
            "Average F1 Score: 0.963886002950845\n",
            "\n",
            "Best Max Depth: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. CODE 1 Time\n"
      ],
      "metadata": {
        "id": "gxHJfaQV_MC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training (60%) and testing (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
        "\n",
        "# Number of repetitions\n",
        "num_repeats = 20\n",
        "# Lists to store results\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "# Define a range of max_depth values to test\n",
        "max_depth_values = [3, 5, 7, 10, 15, 20,25, None]\n",
        "for max_depth in max_depth_values:\n",
        "    f1_scores_iter = []\n",
        "    conf_matrices_iter = []\n",
        "    for _ in range(num_repeats):\n",
        "        # Split the data into training (60%) and testing (40%)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                             test_size=0.4, stratify=y)\n",
        "\n",
        "# Create a Decision Tree classifier with entropy as the criterion and max_depth=None\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42, max_depth=None)\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "# Evaluate the performance using confusion matrix and F1-score\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# Print the confusion matrix and F1 score\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT6GmpeC9u-3",
        "outputId": "242f9c4e-7d37-438b-c329-dee6ac7975f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[146   4   4   0]\n",
            " [  1  25   2   0]\n",
            " [ 10   0 474   0]\n",
            " [  3   3   0  20]]\n",
            "F1 Score: 0.9611546604733567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3 Code 20 times\n"
      ],
      "metadata": {
        "id": "HvquVD6U_Qy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training (60%) and testing (40%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)\n",
        "\n",
        "# Number of repetitions\n",
        "num_repeats = 20\n",
        "# Lists to store results\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "# Define a range of max_depth values to test\n",
        "max_depth_values = [3, 5, 7, 10, 15, 20,25, None]\n",
        "for max_depth in max_depth_values:\n",
        "    f1_scores_iter = []\n",
        "    conf_matrices_iter = []\n",
        "    for _ in range(num_repeats):\n",
        "        # Split the data into training (60%) and testing (40%)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                             test_size=0.2, stratify=y)\n",
        "\n",
        "        # Lists to store results\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "for _ in range(num_repeats):\n",
        "    # Split the data into training (60%) and testing (40%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "    stratify=y)\n",
        "    # Create a Decision Tree classifier with Gini index as the criterion\n",
        "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "    # Train the classifier on the training data\n",
        "    clf.fit(X_train, y_train)\n",
        "    # Make predictions on the test data\n",
        "    y_pred = clf.predict(X_test)\n",
        "    # Evaluate the performance using confusion matrix and F1-score\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    # Store results\n",
        "    conf_matrices.append(conf_matrix)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and print the average F1-score and confusion matrix\n",
        "average_f1 = np.mean(f1_scores, axis=0)\n",
        "average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "print(\"Average Confusion Matrix:\")\n",
        "print(average_conf_matrix.astype(int))\n",
        "print(\"\\nAverage F1 Score:\", average_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6mgrx1G_C7o",
        "outputId": "d6951b9c-f95b-4452-b0b6-49ec05eb818f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Confusion Matrix:\n",
            "[[ 72   0   3   0]\n",
            " [  0  13   0   0]\n",
            " [  3   0 238   0]\n",
            " [  0   0   0  11]]\n",
            "\n",
            "Average F1 Score: 0.9717123331349187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting"
      ],
      "metadata": {
        "id": "Ug0kZO_EAsKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of repetitions\n",
        "num_repeats = 20\n",
        "\n",
        "# Lists to store results\n",
        "f1_scores = []\n",
        "conf_matrices = []\n",
        "# Varying maximum depth values to induce overfitting\n",
        "max_depth_values = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
        "for max_depth in max_depth_values:\n",
        "    f1_scores_depth = []\n",
        "    conf_matrices_depth = []\n",
        "    for _ in range(num_repeats):\n",
        "        # Split the data into training 80\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "    test_size=0.2, stratify=y)\n",
        "        # Create a Decision Tree classifier with Gini index as the criterion\n",
        "        clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=max_depth,\n",
        "random_state=42)\n",
        "    # Train the classifier on the training data\n",
        "    clf.fit(X_train, y_train)\n",
        "    # Make predictions on the test data\n",
        "    y_pred = clf.predict(X_test)\n",
        "    # Evaluate the performance using confusion matrix and F1-score\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    # Store results\n",
        "    conf_matrices_depth.append(conf_matrix)\n",
        "    f1_scores_depth.append(f1)\n",
        "# Calculate and print the average F1-score and confusion matrix for each depth\n",
        "average_f1_depth = np.mean(f1_scores_depth, axis=0)\n",
        "average_conf_matrix_depth = np.mean(conf_matrices_depth, axis=0)\n",
        "print(f\"Results for max_depth={max_depth}:\")\n",
        "print(\"Average Confusion Matrix:\")\n",
        "print(average_conf_matrix_depth.astype(int))\n",
        "print(\"Average F1 Score:\", average_f1_depth)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2quQfAFrAbkT",
        "outputId": "4b4dcdef-b5c5-4219-89ab-d9984e666e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for max_depth=50:\n",
            "Average Confusion Matrix:\n",
            "[[ 75   1   1   0]\n",
            " [  3  10   0   1]\n",
            " [  5   0 237   0]\n",
            " [  2   0   0  11]]\n",
            "Average F1 Score: 0.9621713765788911\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}